# Interpretability of node classification results using StellarGraph

<!-- DOCS LINKS -->
<!-- autogenerated by scripts/demo_indexing.py, edit that file instead of this location -->

These demos are displayed with detailed descriptions in the documentation: https://stellargraph.readthedocs.io/en/stable/demos/interpretability/

| Demo | Source |
|---|---|
| [Interpreting nodes and edges with saliency maps in GAT](https://stellargraph.readthedocs.io/en/stable/demos/interpretability/gat-node-link-importance.html) | [source](gat-node-link-importance.ipynb) |
| [Interpreting nodes and edges with saliency maps in GCN](https://stellargraph.readthedocs.io/en/stable/demos/interpretability/gcn-node-link-importance.html) | [source](gcn-node-link-importance.ipynb) |
| [Interpreting nodes and edges with saliency maps in GCN (sparse)](https://stellargraph.readthedocs.io/en/stable/demos/interpretability/gcn-sparse-node-link-importance.html) | [source](gcn-sparse-node-link-importance.ipynb) |
| [Intepretability on Hateful Twitter Datasets](https://stellargraph.readthedocs.io/en/stable/demos/interpretability/hateful-twitters-interpretability.html) | [source](hateful-twitters-interpretability.ipynb) |

The demo titles link to the latest, nicely rendered version. The 'source' links will open the demo in the application in which this README is being viewed, such as Jupyter Lab (ready for execution).
<!-- DOCS LINKS -->
