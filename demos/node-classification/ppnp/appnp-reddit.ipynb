{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of reddit user posts using graph machine learning with Stellargraph\n",
    "\n",
    "We apply the graph machine algorithm APPNP [1] to the task of classifying reddit user posts into 41 different categories using the dataset published in [2] which can be downloaded [here](http://snap.stanford.edu/graphsage/reddit.zip).  \n",
    "\n",
    "The following is a description of the dataset [2]:\n",
    "\n",
    ">Reddit is a large online discussion forum where users post and comment on content in different topical\n",
    ">communities. We constructed a graph dataset from Reddit posts made in the month of September, 2014. The node label in this case is the community, or “subreddit”, that a post belongs to. We sampled\n",
    ">50 large communities and built a post-to-post graph, connecting posts if the same user comments\n",
    ">on both. In total this dataset contains 232,965 posts with an average degree of 492. We use the first\n",
    ">20 days for training and the remaining days for testing (with 30% used for validation). For features,\n",
    ">we use off-the-shelf 300-dimensional GloVe CommonCrawl word vectors [3]; for each post, we\n",
    ">concatenated (i) the average embedding of the post title, (ii) the average embedding of all the post’s\n",
    ">comments (iii) the post’s score, and (iv) the number of comments made on the post.\n",
    "\n",
    "\n",
    "We demonstrate the advantage of using graph features and the scalability of the APPNP algorithm for node classification on the reddit dataset.  We first train a MLP on the node features and then propagate this model using APPNP.  Training is only done on the node features, this approach allows model training to be completed in under a 1 minute on an 8th gen quad-core i7.\n",
    "\n",
    "\n",
    "**References**\n",
    "\n",
    "1. Predict then propagate: Graph neural networks meet personalized pagerank. J. Klicpera,  A. Bojchevski, & S. Günnemann arxiv:1810.05997, 2018.\n",
    "\n",
    "\n",
    "2. Inductive Representation Learning on Large Graphs. W.L. Hamilton, R. Ying, and J. Leskovec arXiv:1706.02216 [cs.SI], 2017.\n",
    "\n",
    "\n",
    "3. Glove: Global vectors for word representation. J. Pennington, R. Socher, and C. D. Manning. In EMNLP, 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kieranricardo/anaconda3/envs/stellar-demos/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/kieranricardo/anaconda3/envs/stellar-demos/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/kieranricardo/anaconda3/envs/stellar-demos/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/kieranricardo/anaconda3/envs/stellar-demos/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/kieranricardo/anaconda3/envs/stellar-demos/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/kieranricardo/anaconda3/envs/stellar-demos/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/kieranricardo/anaconda3/envs/stellar-demos/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/kieranricardo/anaconda3/envs/stellar-demos/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/kieranricardo/anaconda3/envs/stellar-demos/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/kieranricardo/anaconda3/envs/stellar-demos/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/kieranricardo/anaconda3/envs/stellar-demos/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/kieranricardo/anaconda3/envs/stellar-demos/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "import stellargraph as sg\n",
    "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, SparseFullBatchNodeSequence\n",
    "from stellargraph.layer import GraphSAGE, GCN, GAT, APPNP\n",
    "from stellargraph.layer.appnp import APPNPPropagationLayer\n",
    "from stellargraph import globalvar\n",
    "from stellargraph.core.utils import GCN_Aadj_feats_op\n",
    "\n",
    "from tensorflow.keras import layers, optimizers, losses, metrics, Model, models\n",
    "from sklearn import preprocessing, feature_extraction\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Reddit Dataset\n",
    "\n",
    "First, we load the reddit dataset which is stored as a series of json files.  We first load the graph data and then the node features and labels and ensure that indexing is consistent across the graph, labels, and node features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.expanduser(\"~/data/reddit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, \"reddit-G.json\")) as gfile:\n",
    "    graph_data = json.load(gfile)\n",
    "    \n",
    "list_node_ids = list(d['id'] for d in graph_data['nodes'])\n",
    "\n",
    "edge_generator = ((link['source'], link['target']) for link in graph_data['links'])\n",
    "edge_df = pd.DataFrame(edge_generator, columns=[\"target\", \"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 231443\n",
      "Number of edges: 11606919\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of nodes:\", len(list_node_ids))\n",
    "print(\"Number of edges:\", len(edge_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, \"reddit-class_map.json\")) as tfile:\n",
    "    labels = json.load(tfile)\n",
    "\n",
    "feats = np.load(data_dir + \"/reddit-feats.npy\")\n",
    "\n",
    "feats[:,0] = np.log(feats[:,0]+1.0)\n",
    "feats[:,1] = np.log(feats[:,1]-min(np.min(feats[:,1]), -1))\n",
    "\n",
    "feat_id_map = json.load(open(data_dir + \"/reddit-id_map.json\"))\n",
    "\n",
    "# sort node features to match the order of feat_id_map\n",
    "sorted_idxs = np.array([feat_id_map[key] for key in list_node_ids])\n",
    "feats = feats[sorted_idxs,:]\n",
    "\n",
    "#sort node labnels to match the order of feat_id_map\n",
    "labels = np.array([labels[key] for key in list_node_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_data = pd.DataFrame(feats)\n",
    "\n",
    "target_encoding = preprocessing.OneHotEncoder(sparse=False, categories='auto')\n",
    "targets = target_encoding.fit_transform(labels.reshape(-1, 1))\n",
    "targets = pd.DataFrame(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then split the data into train/val/test based on the labels stored in the dataset. This is the same train/val/test split used in the graphsage paper. Then we fit a standard scaler on only the training data and use it to standardize all of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152410 training nodes.\n",
      "23699 validation nodes.\n",
      "55334 testing nodes.\n"
     ]
    }
   ],
   "source": [
    "def map_node_to_split(node):\n",
    "    if node['test']:\n",
    "        return 'test'\n",
    "    elif node['val']:\n",
    "        return 'val'\n",
    "    else:\n",
    "        return 'train'\n",
    "\n",
    "    \n",
    "train_test_val_dict = dict(zip(list_node_ids, map(map_node_to_split, graph_data['nodes'])))\n",
    "\n",
    "train_mask = [(train_test_val_dict[key] == 'train') for key in list_node_ids]\n",
    "val_mask = [(train_test_val_dict[key] == 'val') for key in list_node_ids]\n",
    "test_mask = [(train_test_val_dict[key] == 'test') for key in list_node_ids]\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(node_data[train_mask].values)\n",
    "node_data.iloc[:, :] = scaler.transform(node_data.values)\n",
    "\n",
    "train_data, train_targets = node_data[train_mask], targets[train_mask]\n",
    "val_data, val_targets = node_data[val_mask], targets[val_mask]\n",
    "test_data, test_targets = node_data[test_mask], targets[test_mask]\n",
    "\n",
    "print(\"{} training nodes.\".format(len(train_data)))\n",
    "print(\"{} validation nodes.\".format(len(val_data)))\n",
    "print(\"{} testing nodes.\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an adjacnecy matrix and StellarGraph generator\n",
    "\n",
    "Standard stellargaph workflows involve creating a stellargaph object and using this to create the data generators. For the large reddit graph this requires approximately 20GB of RAM. This demo has a `low_memory` option which when set to `True` creates the data generator directly from the node features and edge list and only requires approximately 8GB of RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_memory = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adj_from_edgelist(edge_df, nodelist):\n",
    "    '''\n",
    "    This function creates an adjacency matrix directly from an edgelist and a nodelist.\n",
    "    '''\n",
    "    \n",
    "    node_index = dict(zip(nodelist, range(len(nodelist))))\n",
    "    \n",
    "    rows = [node_index[source_node] for source_node in edge_df[\"source\"]]\n",
    "    cols = [node_index[target_node] for target_node in edge_df[\"target\"]]\n",
    "    data = np.ones(len(edge_df), np.float64)\n",
    "    \n",
    "    Aadj = coo_matrix(\n",
    "                (data, (rows, cols)),\n",
    "                shape=(len(nodelist), len(nodelist)),\n",
    "            )\n",
    "    \n",
    "    return Aadj\n",
    "\n",
    "\n",
    "def create_generator_from_edge_df_feats(edge_df, node_data):\n",
    "    '''\n",
    "    This function is a hack that creates stellargaph FullBatchNodeGenerator directly\n",
    "    from an adjacency list and a data frame of node features.\n",
    "    '''\n",
    "    \n",
    "    # create adjacency matrix\n",
    "    \n",
    "    Aadj = create_adj_from_edgelist(edge_df, node_data.index)\n",
    "\n",
    "    _, Aadj = GCN_Aadj_feats_op(\n",
    "                    features=node_data, A=Aadj, method='gcn'\n",
    "        )\n",
    "    \n",
    "    # create a dummy StellarGraph object\n",
    "    gnx = nx.Graph()\n",
    "    gnx.add_nodes_from([\"a\", \"b\"])\n",
    "\n",
    "    gnx.add_edges_from([(\"a\", \"b\")])\n",
    "\n",
    "    gnx = gnx.to_undirected()\n",
    "    features = np.array([[1, 1], [1, 0]])\n",
    "\n",
    "    nodes = gnx.nodes()\n",
    "    features = pd.DataFrame.from_dict(\n",
    "        {n: f for n, f in zip(nodes, features)}, orient=\"index\"\n",
    "    )\n",
    "\n",
    "    G = sg.StellarGraph(gnx, node_type_name=\"node\", node_features=features)\n",
    "    \n",
    "    # create a FullBatchNodeGenerator from the dummy StellarGraph object\n",
    "    generator = FullBatchNodeGenerator(G, method=\"gcn\", sparse=True)\n",
    "    \n",
    "    # manually set FullBatchNodeGenerator attributes\n",
    "    generator.features = node_data\n",
    "    generator.Aadj = Aadj\n",
    "    generator.node_list = list(node_data.index.values)\n",
    "    \n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GCN (local pooling) filters...\n",
      "Using GCN (local pooling) filters...\n"
     ]
    }
   ],
   "source": [
    "if low_memory == True:\n",
    "    \n",
    "    generator = create_generator_from_edge_df_feats(edge_df, node_data)\n",
    "\n",
    "else:\n",
    "    gnx = nx.from_pandas_edgelist(edgelist)\n",
    "    G = sg.StellarGraph(gnx, node_features=node_data)\n",
    "\n",
    "    gnx.clear()\n",
    "    generator = FullBatchNodeGenerator(G, method=\"gcn\", sparse=True)\n",
    "\n",
    "test_gen = generator.flow(test_data.index, test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We now create a MLP and train on the node features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kieranricardo/anaconda3/envs/stellar-demos/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "in_layer = layers.Input(shape=(train_data.shape[-1]))\n",
    "\n",
    "layer = layers.Dense(512, activation='relu', kernel_regularizer=\"l2\")(in_layer)\n",
    "layer = layers.Dropout(0.5)(layer)\n",
    "layer = layers.Dense(512, activation='relu', kernel_regularizer=\"l2\")(in_layer)\n",
    "layer = layers.Dropout(0.5)(layer)\n",
    "\n",
    "#note the dimension of the output should equal the number of classes to predict!\n",
    "layer = layers.Dense(train_targets.shape[-1], activation='softmax')(layer)\n",
    "\n",
    "fully_connected_model = Model(inputs=in_layer, outputs=layer)\n",
    "\n",
    "fully_connected_model.compile(\n",
    "    optimizer=optimizers.Adam(lr=0.0001),\n",
    "    loss=losses.categorical_crossentropy,\n",
    "    metrics=[\"acc\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = fully_connected_model.fit(\n",
    "    train_data, train_targets,\n",
    "    epochs = 60,\n",
    "    validation_data = (val_data, val_targets),\n",
    "    batch_size = 300,\n",
    "    verbose = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MLP attains an accuracy of ~70% on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55334/55334 [==============================] - 2s 27us/sample - loss: 1.1751 - acc: 0.7209\n",
      "\n",
      "Test Set Metrics:\n",
      "\tloss: 1.1751\n",
      "\tacc: 0.7209\n"
     ]
    }
   ],
   "source": [
    "test_metrics = fully_connected_model.evaluate(test_data, test_targets)\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "for name, val in zip(fully_connected_model.metrics_names, test_metrics):\n",
    "    print(\"\\t{}: {:0.4f}\".format(name, val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPNP Propagation\n",
    "\n",
    "We now create an APPNP model and propagate the MLP. No further training is happening in this step.  We then test the propagated model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method SqueezedSparseConversion.call of <stellargraph.layer.misc.SqueezedSparseConversion object at 0x13fc08160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SqueezedSparseConversion.call of <stellargraph.layer.misc.SqueezedSparseConversion object at 0x13fc08160>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method SqueezedSparseConversion.call of <stellargraph.layer.misc.SqueezedSparseConversion object at 0x13fc08160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SqueezedSparseConversion.call of <stellargraph.layer.misc.SqueezedSparseConversion object at 0x13fc08160>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc01828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc01828>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc01828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc01828>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc01a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc01a20>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc01a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc01a20>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc01c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc01c18>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc01c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc01c18>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc01eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc01eb8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc01eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc01eb8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc040f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc040f0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc040f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc040f0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc042e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc042e8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc042e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc042e8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc044e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc044e0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc044e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc044e0>>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc046d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc046d8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc046d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc046d8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc048d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc048d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc048d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc048d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc04ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc04ac8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc04ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method APPNPPropagationLayer.call of <stellargraph.layer.appnp.APPNPPropagationLayer object at 0x13fc04ac8>>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    }
   ],
   "source": [
    "appnp = APPNP(layer_sizes=[train_targets.shape[-1]], \n",
    "              activations=['relu'], \n",
    "              bias=True,\n",
    "              generator=generator, \n",
    "              teleport_probability=0.2, \n",
    "              dropout=0.5, \n",
    "              kernel_regularizer='l2'\n",
    ")\n",
    "\n",
    "x_inp, x_out = appnp.propagate_model(fully_connected_model)\n",
    "predictions = layers.Softmax()(x_out)\n",
    "\n",
    "propagated_model = Model(inputs=x_inp, outputs=predictions)\n",
    "propagated_model.compile(loss='categorical_crossentropy', metrics=['acc'],\n",
    "                  optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Metrics:\n",
      "\tloss: 3.5071\n",
      "\tacc: 0.8952\n"
     ]
    }
   ],
   "source": [
    "test_metrics = propagated_model.evaluate_generator(test_gen)\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "for name, val in zip(propagated_model.metrics_names, test_metrics):\n",
    "    print(\"\\t{}: {:0.4f}\".format(name, val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propagating the MLP with APPNP increases the test set accuracy by ~15% without any further training. As we are performing single-label multiclass classification the accuracy is equivalent to the micro F1 metric. This micro F1 is comparable to that attained in the GraphSAGE paper [2]. GraphSAGE with LSTM aggregation attains a best supervised F1 of 0.95 in [2], however APPNP only required ~3 minutes of training on an 8th gen i7 compared to the hours required for GraphSAGE while still attaining a similar F1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
